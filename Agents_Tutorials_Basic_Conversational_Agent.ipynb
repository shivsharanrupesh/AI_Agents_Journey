{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOll2U7sjTAwXu8IFJyl5vV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivsharanrupesh/GenAI_Agents_Journey/blob/main/Agents_Tutorials_Basic_Conversational_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Building a Conversational Agent with Context Awareness\n",
        "Overview**  \n",
        "\n",
        "This tutorial describes how to build a conversational agent that can keep track of conversations from one interaction to the next. We use a modern AI framework to build an agent capable of more natural and coherent conversations.\n",
        "\n",
        " **Motivation**\n",
        "\n",
        "Lots of simple chatbots do not maintain any context, which often creates angering experiences for the user. Our goal in this tutorial is to remedy this consideration by constructing a conversational agent that can recall parts of the conversation and refer to them later to enhance the interaction experience.\n",
        "\n",
        " **Key Components**\n",
        "\n",
        " 1. **Language Model**: The central AI component that generates responses.\n",
        "\n",
        " 2. **Prompt Template**: Unique structure of how we interact.\n",
        "\n",
        " 3. **History Manager**: Responsible for managing conversation context as well as historical contexts.\n",
        "\n",
        " 4. **Message Store**: Responsible for storing messages for each conversation session.\n",
        "\n",
        "\n",
        " **Methods and Procedures**\n",
        "\n",
        " **Setting Up the Environment**\n",
        "\n",
        "AI frameworks will be laid out to help start and ensure access to an appropriate language model. This is very much the foundation for our conversation agent.\n",
        "\n",
        " **Creating the Chat History Storage**\n",
        "\n",
        "This sets up a way to manage multiple conversations. Each iteration may be uniquely identified and allowed its own message history.\n",
        "\n",
        " **Creating the Format of the Conversation**\n",
        "\n",
        " **Create a structure that will utilize:**\n",
        "\n",
        "1. A system message that specifies the role of the AI\n",
        "2. A placeholder for historical conversation;\n",
        "The input provided by the user.\n",
        "\n",
        "This structure will guide the AI into responding while also keeping a sense of continuity through the conversation.\n",
        "\n",
        "**Creating the Conversational Chain**\n",
        "\n",
        "Combine the converse template with the language model to create a simple conversational chain. Now wrap this chain with a history manager that automatically takes care of insertion and retrieval of conversation history.\n",
        "\n",
        "**Interacting with the Agent**\n",
        "\n",
        "The agent can be used by invoking it with a user input and a session identifier. The history manager is responsible for fetching the conversation history to be inserted into the prompt and storing incoming messages after every interaction.\n",
        "\n",
        " **Conclusion**\n",
        "\n",
        "This methodology of developing a conversational agent has several advantages:\n",
        "1. **Context awareness** allows the agent to refer to previous portions of the conversation, promoting more natural interactions.\n",
        "2. **Simplicity**: Modular design allows for basic implementation.\n",
        "3. **Flexibility:** Easy to change conversational structures or switch the underlying language model.\n",
        "4. **Scalability:** A session-based approach allows for dealing with several independent conversations.\n",
        "\n",
        " **Further improvement can be implemented in the agent, guided by:**\n",
        "\n",
        "1. Further prompt engineering.\n",
        "2. Integration with external knowledge bases.\n",
        "3. Adding specialized capabilities for particular domains.\n",
        "4. Incorporating error handling and conversation repair strategies.\n",
        "\n",
        "This design fundamentally builds upon the premise of context management enabling this conversational agent to vastly improve upon very basic chatbot functionality and thus, open up avenues for more engaging and helpful AI assistants.\n",
        "\n",
        "\n",
        " **Conversational Agent Tutorial**\n",
        "\n",
        "In this notebook, we shall demonstrate the building of a simple conversational agent using LangChain.\n",
        "\n",
        " **Import Libraries:**"
      ],
      "metadata": {
        "id": "FX5KRSdQOi49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install langchain langchain_experimental openai python-dotenv langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxyp4AzARWUG",
        "outputId": "6dda58d5-9ce8-481e-a6f6-fd22dbd53b31"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Collecting langchain_experimental\n",
            "  Using cached langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain_experimental)\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Collecting langchain-core<1.0.0,>=0.3.34 (from langchain)\n",
            "  Downloading langchain_core-0.3.37-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.37-py3-none-any.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, pydantic-settings, dataclasses-json, langchain-core, langchain_openai, langchain, langchain-community, langchain_experimental\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.35\n",
            "    Uninstalling langchain-core-0.3.35:\n",
            "      Successfully uninstalled langchain-core-0.3.35\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.18\n",
            "    Uninstalling langchain-0.3.18:\n",
            "      Successfully uninstalled langchain-0.3.18\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.19 langchain-community-0.3.18 langchain-core-0.3.37 langchain_experimental-0.3.4 langchain_openai-0.3.6 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "C6rAlKJFTn31"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Initialize the Model**"
      ],
      "metadata": {
        "id": "WxyUgTfzUfCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=api_key)\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    api_key=api_key,\n",
        "    max_tokens=500,\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "heVEDxsQUlTx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Create a Simple in-memory store for chat histories**"
      ],
      "metadata": {
        "id": "-OfuHgNoWeXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store = {}\n",
        "\n",
        "def get_chat_history(session_id):\n",
        "    \"\"\"\n",
        "    Retrieves or creates a chat history for a given session ID.\n",
        "\n",
        "    This function manages chat histories for multiple sessions using an in-memory store.\n",
        "    If the session ID does not already exist in the store, a new `ChatMessageHistory`\n",
        "    object is created and associated with the session ID. Otherwise, the existing\n",
        "    chat history for the session is returned.\n",
        "\n",
        "    Args:\n",
        "        session_id (str): A unique identifier for the session. This is used to\n",
        "                          retrieve or create the corresponding chat history.\n",
        "\n",
        "    Returns:\n",
        "        ChatMessageHistory: A `ChatMessageHistory` object containing the chat history\n",
        "                           for the specified session. If the session ID is new, an\n",
        "                           empty `ChatMessageHistory` object is returned.\n",
        "\n",
        "    Example:\n",
        "        >>> session_id = \"user_123\"\n",
        "        >>> chat_history = get_chat_history(session_id)\n",
        "        >>> chat_history.add_user_message(\"Hello!\")\n",
        "        >>> chat_history.add_ai_message(\"Hi there!\")\n",
        "        >>> print(chat_history.messages)\n",
        "        [HumanMessage(content=\"Hello!\"), AIMessage(content=\"Hi there!\")]\n",
        "    \"\"\"\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]"
      ],
      "metadata": {
        "id": "PP_xVmwvWk4O"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create the prompt template**"
      ],
      "metadata": {
        "id": "tbFv7Gm-Xqb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])"
      ],
      "metadata": {
        "id": "rkKvw_x0XtZB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combine the prompt and model into a runnable chain**"
      ],
      "metadata": {
        "id": "wV2nflmjXkNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "hxaj5T9WXpKK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wrap the chain with message history**"
      ],
      "metadata": {
        "id": "fqS9FEY9YO3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "A chain enhanced with chat history functionality.\n",
        "\n",
        "This wrapper adds the ability to maintain and utilize chat history for a given session.\n",
        "It retrieves or creates a chat history for each session using the `get_chat_history`\n",
        "function and ensures that the history is passed to the chain for context-aware responses.\n",
        "\n",
        "Args:\n",
        "    chain: The base chain (e.g., a chatbot or LLM pipeline) to enhance with chat history.\n",
        "    get_chat_history: A function that retrieves or creates a chat history for a session.\n",
        "    input_messages_key (str): The key in the input dictionary where the user's message is located.\n",
        "    output_messages_key (str): The key in the output dictionary where the chat history is stored.\n",
        "\n",
        "Example:\n",
        "    >>> response = chain_with_history.invoke(\n",
        "    ...     {\"input\": \"Hello!\"},\n",
        "    ...     config={\"configurable\": {\"session_id\": \"user_123\"}}\n",
        "    ... )\n",
        "    >>> print(response)\n",
        "    {\"output\": \"Hi there!\", \"history\": [...]}\n",
        "\"\"\"\n",
        "\n",
        "chain_with_history = RunnableWithMessageHistory(\n",
        "    chain, get_chat_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\"\n",
        ")"
      ],
      "metadata": {
        "id": "7oxovD_dYOJf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_1 = chain_with_history.invoke(\n",
        "    {\"input\": \"Hello! How's it going, whats whether out there? \"},\n",
        "    config={\"configurable\": {\"session_id\": \"user_123\"}}\n",
        ")\n",
        "print(\"AI:\", response_1.content)\n",
        "\n",
        "response_2 = chain_with_history.invoke(\n",
        "    {\"input\": \"What was my previous message?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"user_123\"}}\n",
        ")\n",
        "print(\"AI:\", response_2.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry3o-F5vZtLg",
        "outputId": "3f700823-dcf4-4295-f8a0-464d1925126e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: I'm an artificial intelligence and don't have the ability to perceive the environment or weather. However, you can check the weather in your area by using a weather app or website. Can I assist you with anything else?\n",
            "AI: Your previous message was: \"Hello! How's it going, whats whether out there?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Print the conversation history**"
      ],
      "metadata": {
        "id": "r7iCtTd-cW_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Convseration History: \")\n",
        "for message in store[\"user_123\"].messages:\n",
        "    print(f\"{message.type}: {message.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkpV86JlcZ3Y",
        "outputId": "09cda2ac-4833-4581-cdfb-8d50181f7425"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Convseration History: \n",
            "human: Hello!\n",
            "ai: Hello! How can I assist you today?\n",
            "human: What was my old message!\n",
            "ai: I'm sorry, but as an AI, I don't have the ability to access or retrieve past interactions unless they are part of the current conversation. How can I assist you further?\n",
            "human: Hello! How's it going, whats whether out there? \n",
            "ai: As an artificial intelligence, I don't have the ability to experience weather or check real-time conditions. However, you can check the weather by using a weather app or website, or by asking a voice-activated device like Google Home or Amazon Echo, if you have one.\n",
            "human: What was my old message!\n",
            "ai: I'm sorry for any confusion, but as an AI, I don't have the ability to access or retrieve past interactions unless they are part of the current conversation. Can I assist you with anything else?\n",
            "human: Hello! How's it going, whats whether out there? \n",
            "ai: I'm an artificial intelligence and don't have the ability to perceive the environment or weather. However, you can check the weather in your area by using a weather app or website. Can I assist you with anything else?\n",
            "human: What was my previous message?\n",
            "ai: Your previous message was: \"Hello! How's it going, whats whether out there?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J6IrpkR4c0f-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}